import bql
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import re
import warnings
from datetime import datetime
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller

warnings.simplefilter(action='ignore', category=FutureWarning)

print("\n[OK] Spread Analysis running...")

# =============================================================================
# (1) PARAMETERS
# =============================================================================
pair = "EURUSD"
tenors = ["1M", "2M", "3M", "6M", "9M", "1Y"]
start_date = "2023-06-01"
end_date = datetime.today()
rolling_window = 100
TOP_N = 15

# Deltas => user-friendly labels
delta_map = {
    "Call10": "10D Call",
    "Call25": "25D Call",
    "ATM":    "ATM",
    "Put25":  "25D Put",
    "Put10":  "10D Put"
}
delta_order = ["Call10", "Call25", "ATM", "Put25", "Put10"]

# Color scale (NxN heatmap)
my_scale = [
    [0.00, "#FF0000"],
    [0.25, "#D8BFD8"],
    [0.50, "#A9A9F5"],
    [0.75, "#87CEFA"],
    [1.00, "#4169E1"]
]

# Plotly layout for the NxN heatmap
layout_conf = dict(
    template="plotly_dark",
    width=1400,
    height=1400,
    margin=dict(l=60, r=80, t=80, b=60),
    dragmode='pan',
    xaxis=dict(gridcolor="rgba(55,55,55,1)", gridwidth=0.5, tickfont=dict(size=14)),
    yaxis=dict(gridcolor="rgba(55,55,55,1)", gridwidth=0.5, tickfont=dict(size=14)),
    legend=dict(
        orientation='v', x=1.02, y=0.5, xanchor='left', yanchor='middle',
        bgcolor='rgba(15,15,15,0.6)', bordercolor='rgba(200,200,200,0.4)', borderwidth=1,
        font=dict(color='white', size=12), itemsizing='constant', tracegroupgap=10
    ),
)

def update_fig_title(fig, title_text):
    # Central and bold
    fig.update_layout(
        title=dict(
            text=f"<b>{title_text}</b>",
            x=0.5,
            xanchor="center",
            font=dict(size=18, color="white", family="Arial Black")
        )
    )
    fig.update_layout(**layout_conf)

# -----------------------------------------------------------------------------
# Plotly config for interactive use
# -----------------------------------------------------------------------------
plotly_config = dict(scrollZoom=True)

# -----------------------------------------------------------------------------
# Mappings for volatility columns (used later in trade suggestions)
# -----------------------------------------------------------------------------
volatility_columns = {
    "10D Call": "Call10",
    "25D Call": "Call25",
    "ATM":      "ATM",
    "25D Put":  "Put25",
    "10D Put":  "Put10"
}

# =============================================================================
# (2) DATA EXTRACTION
# =============================================================================
bq_svc = bql.Service()
tickers = [f"{pair} BGN Curncy"]
for t in tenors:
    # Forwards and vol surfaces
    tickers.append(f"{pair}{'12M' if t == '1Y' else t} BGN Curncy")   # Fwd
    tickers.append(f"{pair}V{'1Y' if t == '1Y' else t} BGN Curncy")  # ATM
    tickers.append(f"{pair}25R{'1Y' if t == '1Y' else t} BGN Curncy")# 25D RR
    tickers.append(f"{pair}25B{'1Y' if t == '1Y' else t} BGN Curncy")# 25D BF
    tickers.append(f"{pair}10R{'1Y' if t == '1Y' else t} BGN Curncy")# 10D RR
    tickers.append(f"{pair}10B{'1Y' if t == '1Y' else t} BGN Curncy")# 10D BF

px_item = bq_svc.data.px_last(dates=bq_svc.func.range(start_date, end_date))
req = bql.Request(tickers, px_item)
resp = bq_svc.execute(req)

df_raw = resp[0].df().reset_index()
px_cols = [c for c in df_raw.columns if "PX_LAST" in c.upper()]
if not px_cols:
    raise SystemExit("No PX_LAST column found.")
df_raw.rename(columns={px_cols[0]: "Value"}, inplace=True)

def detect_cat(tic: str):
    up = tic.upper()
    if "V" in up:
        return "ATM_vol"
    elif "25R" in up or "10R" in up:
        return "RR"
    elif "25B" in up or "10B" in up:
        return "BF"
    return "Other"

def extract_tenor(tic: str):
    m = re.search(r"(\d+[WMY])", tic.upper())
    return m.group(1) if m else np.nan

df_raw["Category"] = df_raw["ID"].apply(detect_cat)
df_raw["Tenor"] = df_raw["ID"].apply(extract_tenor)
df_raw["DATE"] = pd.to_datetime(df_raw["DATE"])

df_raw = df_raw[df_raw["DATE"].dt.dayofweek < 5]
df_raw = df_raw[df_raw["DATE"] >= pd.to_datetime(start_date)]
df_raw = df_raw[df_raw["DATE"] <= pd.to_datetime(end_date)]
df_raw.sort_values(["DATE", "Tenor"], inplace=True)

# =============================================================================
# (3) CALCULATION OF WINGS (10D/25D, call/put)
# =============================================================================
atm_df = df_raw[df_raw["Category"] == "ATM_vol"][["DATE", "Tenor", "Value"]].copy()
atm_df.rename(columns={"Value": "ATM"}, inplace=True)

rr25_df = df_raw[(df_raw["Category"] == "RR") & (df_raw["ID"].str.contains("25R"))].copy()
rr25_df.rename(columns={"Value": "RR25"}, inplace=True)

bf25_df = df_raw[(df_raw["Category"] == "BF") & (df_raw["ID"].str.contains("25B"))].copy()
bf25_df.rename(columns={"Value": "BF25"}, inplace=True)

rr10_df = df_raw[(df_raw["Category"] == "RR") & (df_raw["ID"].str.contains("10R"))].copy()
rr10_df.rename(columns={"Value": "RR10"}, inplace=True)

bf10_df = df_raw[(df_raw["Category"] == "BF") & (df_raw["ID"].str.contains("10B"))].copy()
bf10_df.rename(columns={"Value": "BF10"}, inplace=True)

def safe_merge(left, right, on=["DATE", "Tenor"]):
    return left.merge(right, on=on, how="outer")

df_merge = atm_df
for sub_df in [rr25_df, bf25_df, rr10_df, bf10_df]:
    df_merge = safe_merge(df_merge, sub_df)
df_merge.sort_values(["DATE", "Tenor"], inplace=True)

def call_put(atm, rr, bf):
    if pd.isna(atm) or pd.isna(rr) or pd.isna(bf):
        return np.nan, np.nan
    c = atm + 0.5 * rr + bf
    p = atm - 0.5 * rr + bf
    return c, p

df_merge["Call25"] = np.nan
df_merge["Put25"]  = np.nan
df_merge["Call10"] = np.nan
df_merge["Put10"]  = np.nan

for idx in df_merge.index:
    atm_  = df_merge.at[idx, "ATM"]
    rr25_ = df_merge.at[idx, "RR25"]
    bf25_ = df_merge.at[idx, "BF25"]
    rr10_ = df_merge.at[idx, "RR10"]
    bf10_ = df_merge.at[idx, "BF10"]
    c25, p25 = call_put(atm_, rr25_, bf25_)
    c10, p10 = call_put(atm_, rr10_, bf10_)
    df_merge.at[idx, "Call25"] = c25
    df_merge.at[idx, "Put25"]  = p25
    df_merge.at[idx, "Call10"] = c10
    df_merge.at[idx, "Put10"]  = p10

# =============================================================================
# (4) LONG TABLE => PIVOT
# =============================================================================
df_long = []
for idx, row in df_merge.iterrows():
    date_ = row["DATE"]
    tn    = row["Tenor"]
    if pd.isna(tn):
        continue
    d_map = {
        "Call10": row["Call10"],
        "Call25": row["Call25"],
        "ATM":    row["ATM"],
        "Put25":  row["Put25"],
        "Put10":  row["Put10"]
    }
    for key in delta_order:
        vol_ = d_map[key]
        if pd.notna(vol_):
            label = delta_map[key]
            instr = f"{label}_{tn}"
            df_long.append((date_, instr, vol_))

df_vol = pd.DataFrame(df_long, columns=["DATE", "Instrument", "Vol"])
df_pivot = df_vol.pivot(index="DATE", columns="Instrument", values="Vol")
df_pivot.sort_index(inplace=True)

# =============================================================================
# (5) SORT THE COLUMNS
# =============================================================================
label_order = ["10D Call", "25D Call", "ATM", "25D Put", "10D Put"]

def parse_instrument_name(instr: str):
    parts = instr.split("_")
    if len(parts) != 2:
        return (999, 999)
    dLabel, tenorStr = parts
    try:
        d_val = label_order.index(dLabel)
    except:
        d_val = 999

    def tenor_float(tn: str) -> float:
        up = tn.upper()
        if "W" in up:
            return float(up[:-1]) / 52
        elif "M" in up:
            return float(up[:-1]) / 12
        elif "Y" in up:
            return float(up[:-1])
        return 999

    t_val = tenor_float(tenorStr)
    return (d_val, t_val)

col_sorted = sorted(df_pivot.columns, key=lambda c: parse_instrument_name(c))
df_pivot = df_pivot[col_sorted]

instruments = df_pivot.columns.tolist()
n_inst = len(instruments)

# =============================================================================
# (6) HELPER FUNCTIONS
# =============================================================================
def rolling_zscore(series, window=100):
    rm = series.rolling(window=window, min_periods=window).mean()
    rs = series.rolling(window=window, min_periods=window).std()
    return (series - rm) / rs, rm, rs

def compute_AR1_half_life(series: pd.Series) -> float:
    s = series.dropna()
    if len(s) < 5:
        return np.nan
    Y = s[1:].values
    X = s[:-1].values
    X = sm.add_constant(X)
    if len(Y) != len(X):
        return np.nan
    model = sm.OLS(Y, X, missing='drop')
    res = model.fit()
    if len(res.params) < 2:
        return np.nan
    phi = res.params[1]
    if abs(phi) >= 1:
        return np.nan
    return -np.log(2) / np.log(abs(phi))

if df_pivot.empty:
    print("No data => abort.")
    import sys
    sys.exit()

last_date = df_pivot.index[-1]

# =============================================================================
# (7) BUILD THE SPREAD MATRIX AND PAIRS_INFO
# =============================================================================
spread_mat = np.full((n_inst, n_inst), np.nan, dtype=float)
pairs_info = []

for i in range(n_inst):
    for j in range(n_inst):
        if i == j:
            continue
        shortInst = instruments[i]
        longInst  = instruments[j]
        spread_ser = df_pivot[longInst] - df_pivot[shortInst]

        z_ser, rmean, rstd = rolling_zscore(spread_ser, rolling_window)
        z_val = np.nan
        last_spread = np.nan
        last_mean = np.nan
        if last_date in z_ser.index:
            z_val = z_ser.loc[last_date]
            last_spread = spread_ser.loc[last_date]
            last_mean = rmean.loc[last_date] if last_date in rmean.index else np.nan

        spread_mat[i, j] = z_val
        hl = compute_AR1_half_life(spread_ser)
        if pd.notna(z_val):
            pairs_info.append(dict(
                short=shortInst,
                long=longInst,
                Z=z_val,
                Spread=last_spread,
                Mean=last_mean,
                HalfLife=hl
            ))

# =============================================================================
# (8) SHOW THE NxN HEATMAP MATRIX FIRST
# =============================================================================
df_z = pd.DataFrame(spread_mat, index=instruments, columns=instruments)
fig_heatmap = px.imshow(
    df_z,
    x=instruments,
    y=instruments,
    origin="lower",
    color_continuous_scale=my_scale,
    range_color=(-3, 3),
    labels=dict(color="Z-Score"),
    width=1500,
    height=1500,
    template="plotly_dark"
)

# Numeric annotations
annotations = []
for i in range(n_inst):
    for j in range(n_inst):
        val = df_z.iloc[i, j]
        if pd.notna(val):
            txt = f"{val:.1f}"
            annotations.append(dict(
                x=instruments[j], y=instruments[i],
                text=txt, showarrow=False,
                font=dict(color="white", size=11),
                xref="x", yref="y", xanchor="center", yanchor="middle"
            ))

col_deltas = [instr.split("_", 1)[0] for instr in instruments]
delta_boundaries = []
for x in range(n_inst - 1):
    if col_deltas[x] != col_deltas[x + 1]:
        delta_boundaries.append(x + 0.5)

shapes_list = []
for bnd in delta_boundaries:
    shapes_list.append(dict(
        type="line",
        x0=bnd, x1=bnd,
        y0=0, y1=n_inst,
        xref="x", yref="y",
        line=dict(color="black", width=2)
    ))
    shapes_list.append(dict(
        type="line",
        y0=bnd, y1=bnd,
        x0=0, x1=n_inst,
        xref="x", yref="y",
        line=dict(color="black", width=2)
    ))

fig_heatmap.update_layout(
    shapes=shapes_list,
    annotations=annotations,
    title=dict(text=f"<b>{pair} - Full Z-Score Matrix (Deltaâ†’Tenors) rolling={rolling_window}</b>", x=0.5, xanchor="center"),
    **layout_conf
)
fig_heatmap.update_xaxes(side="top")
fig_heatmap.update_yaxes(autorange="reversed")
fig_heatmap.show(config={"scrollZoom": True})

# =============================================================================
# (9) TESTING SPREAD STATIONARITY (ADF on RAW SPREAD) + BUILDING TABLE
# =============================================================================
common_layout_conf = dict(
    template="plotly_dark",
    autosize=False,
    width=1400,
    height=650,
    margin=dict(l=60, r=80, t=80, b=60),
    dragmode="pan",
    xaxis=dict(gridcolor="rgba(255,255,255,0.3)", gridwidth=0.25, tickfont=dict(size=14)),
    yaxis=dict(gridcolor="rgba(255,255,255,0.3)", gridwidth=0.25, tickfont=dict(size=14)),
    legend=dict(
        orientation="v", x=1.02, y=0.5, xanchor="left", yanchor="middle",
        bgcolor="rgba(15,15,15,0.6)", bordercolor="rgba(200,200,200,0.4)", borderwidth=1,
        font=dict(color="white", size=12), itemsizing="constant", tracegroupgap=10
    ),
)

def trade_suggestion(z, short_inst, long_inst):
    """If z>0 => Sell longInst, Buy shortInst. Else Sell shortInst, Buy longInst."""
    if z > 0:
        return f"Sell {long_inst}", f"Buy {short_inst}"
    else:
        return f"Sell {short_inst}", f"Buy {long_inst}"

pairs_info.sort(key=lambda d: abs(d["Z"]), reverse=True)
unique_suggestions = set()
trade_suggestions = []

fig_spreads = go.Figure()
fig_zscores = go.Figure()
suggestion_count = 0

for rowd in pairs_info:
    if suggestion_count >= TOP_N:
        break

    z_   = rowd["Z"]
    sp_  = rowd["Spread"]
    mn_  = rowd["Mean"]
    hl_  = rowd["HalfLife"]
    sI   = rowd["short"]
    lI   = rowd["long"]

    sell, buy = trade_suggestion(z_, sI, lI)
    sell_action, sell_instr = sell.split(" ", 1)
    buy_action,  buy_instr  = buy.split(" ", 1)
    sell_label, sell_tenor  = sell_instr.split("_")
    buy_label,  buy_tenor   = buy_instr.split("_")

    new_sell = f"{sell_action} {sell_tenor} {sell_label}"
    new_buy  = f"{buy_action} {buy_tenor} {buy_label}"

    df_filtered = df_merge[df_merge["DATE"] == last_date]
    if df_filtered.empty:
        volatility_buy  = np.nan
        volatility_sell = np.nan
    else:
        df_buy_sub  = df_filtered[df_filtered["Tenor"] == buy_tenor]
        df_sell_sub = df_filtered[df_filtered["Tenor"] == sell_tenor]
        volatility_buy = (
            df_buy_sub[volatility_columns[buy_label]].values[0]
            if (not df_buy_sub.empty and buy_label in volatility_columns)
            else np.nan
        )
        volatility_sell = (
            df_sell_sub[volatility_columns[sell_label]].values[0]
            if (not df_sell_sub.empty and sell_label in volatility_columns)
            else np.nan
        )

    suggestion_id = tuple(sorted([sI, lI]))
    if suggestion_id in unique_suggestions:
        continue
    else:
        unique_suggestions.add(suggestion_id)
        suggestion_count += 1

    # Retrieve the entire spread series if available
    if sI in df_pivot.columns and lI in df_pivot.columns:
        spread_series = df_pivot[lI] - df_pivot[sI]

        # We'll also compute the z_series just for plotting
        z_series, _, _ = rolling_zscore(spread_series, window=rolling_window)

        last_spread_val = spread_series.dropna().iloc[-1] if not spread_series.dropna().empty else np.nan
        last_z_val      = z_series.dropna().iloc[-1]       if not z_series.dropna().empty       else np.nan

        spread_name = f"({lI}-{sI}) {last_spread_val:.2f}" if not np.isnan(last_spread_val) else f"({lI}-{sI})"
        z_name      = f"Z({lI}-{sI}) {last_z_val:.2f}"     if not np.isnan(last_z_val) else f"Z({lI}-{sI})"

        # Plot the raw spread
        fig_spreads.add_trace(
            go.Scatter(
                x=df_pivot.index, y=spread_series,
                mode="lines", name=spread_name,
                line=dict(width=1)
            )
        )
        # Plot the Z-score
        fig_zscores.add_trace(
            go.Scatter(
                x=df_pivot.index, y=z_series,
                mode="lines", name=z_name,
                line=dict(width=1)
            )
        )

        # ADF test on the RAW spread
        spread_clean = spread_series.dropna()
        if not spread_clean.empty:
            adf_res = adfuller(spread_clean)
            p_value = adf_res[1]
            interpretation = "Stationary" if p_value < 0.05 else "Non-Stationary"
        else:
            p_value = np.nan
            interpretation = "Insufficient data"
    else:
        p_value = np.nan
        interpretation = "Missing columns => No test"

    trade_suggestions.append({
        "shortInst": sI,
        "longInst":  lI,
        "Z-Score":   z_,
        "Buy":       new_buy,
        "Sell":      new_sell,
        "Spread":    sp_,
        "Mean":      mn_,
        "Half-Life": hl_,
        "Volatility Buy":  volatility_buy,
        "Volatility Sell": volatility_sell,
        "ADF P-Value":     p_value,
        "Interpretation":  interpretation
    })

# TABLE: top suggestions, with ADF test on RAW spread
headers = [
    "Z-Score", "Leg 2 (Buy)", "Vol (Buy)", "Leg 1 (Sell)", "Vol (Sell)",
    "Vol Sprd", "Avg Sprd in Vol", "Half-Life (days)", "ADF P-Value", "Interpretation"
]

zscore_list = [f"{row['Z-Score']:.2f}" for row in trade_suggestions]
buy_list    = [row["Buy"] for row in trade_suggestions]
vol_buy_list = [
    f"{row['Volatility Buy']:.2f}" if not np.isnan(row['Volatility Buy']) else "NaN"
    for row in trade_suggestions
]
sell_list   = [row["Sell"] for row in trade_suggestions]
vol_sell_list = [
    f"{row['Volatility Sell']:.2f}" if not np.isnan(row['Volatility Sell']) else "NaN"
    for row in trade_suggestions
]
spread_list = [f"{row['Spread']:.2f}" for row in trade_suggestions]
mean_list   = [f"{row['Mean']:.2f}" for row in trade_suggestions]
hlife_list  = [
    f"{row['Half-Life']:.1f}" if not np.isnan(row['Half-Life']) else "NaN"
    for row in trade_suggestions
]
adf_list    = [
    f"{row['ADF P-Value']:.4f}" if not np.isnan(row['ADF P-Value']) else "NaN"
    for row in trade_suggestions
]
interp_list = [row["Interpretation"] for row in trade_suggestions]

col_values = [
    zscore_list,
    buy_list,
    vol_buy_list,
    sell_list,
    vol_sell_list,
    spread_list,
    mean_list,
    hlife_list,
    adf_list,
    interp_list
]

n_rows = len(trade_suggestions)
font_colors = [
    ["white"]       * n_rows,
    ["limegreen"]   * n_rows,
    ["white"]       * n_rows,
    ["red"]         * n_rows,
    ["white"]       * n_rows,
    ["orange"]      * n_rows,
    ["lightskyblue"]* n_rows,
    ["orange"]      * n_rows,
    ["lightpink"]   * n_rows,
    ["lightblue"]      * n_rows
]

fig_table = go.Figure(
    data=[go.Table(
        header=dict(
            values=headers,
            fill_color="rgba(55,55,55,1)",
            align="center",
            font=dict(color="white", size=12)
        ),
        cells=dict(
            values=col_values,
            fill_color="rgba(40,40,40,1)",
            align="center",
            font=dict(color=font_colors, size=11)
        )
    )]
)
fig_table.update_layout(
    template="plotly_dark",
    title=dict(text=f"<b>{pair} - Top {TOP_N} Vol Spread + Stationarity Test (ADF on Raw Spread)</b>", x=0.5, xanchor="center"),
    width=1300,
    height=600
)
fig_table.show(config=plotly_config)

# Finally, show the Spreads and Z-Scores graphs
zero_line = dict(
    type="line",
    xref="paper",
    x0=0,
    x1=1,
    yref="y",
    y0=0,
    y1=0,
    line=dict(color="red", width=1, dash="solid")
)

fig_spreads.update_layout(
    **common_layout_conf,
    title=dict(text=f"<b>{pair} - Top {TOP_N} Spreads (Raw) Historical</b>", x=0.5, xanchor="center"),
    shapes=[zero_line]
)
fig_spreads.show(config=plotly_config)

fig_zscores.update_layout(
    **common_layout_conf,
    title=dict(text=f"<b>{pair} - Top {TOP_N} Z-Scores (rolling={rolling_window})</b>", x=0.5, xanchor="center"),
    shapes=[zero_line]
)
fig_zscores.show(config=plotly_config)

print("\n[OK] Script complete. NxN matrix => Table => Graphs (Spreads & Z-Scores).")
