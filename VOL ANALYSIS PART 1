import bql
import pandas as pd
import numpy as np
import plotly.express as px
import re
from datetime import datetime

# Ajout de statsmodels pour AR(1) et ADF
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller

# =============================================================================
# PARAMÈTRES GLOBAUX & CONFIGURATION
# =============================================================================
pair = "USDCAD"
tenors = ["1M", "2M", "3M", "6M", "9M", "1Y"]
start_date = '2023-01-18'
end_date = datetime.today()

rolling_windows = [100]    
realized_windows = [5, 10, 30, 90]
spot_return_threshold = 0.002

title_spot            = f"{pair} - Spot"
title_atm_vol         = f"{pair} - ATM Vol"
title_25d_rr          = f"{pair} - 25D Risk Reversal"
title_25d_bf          = f"{pair} - 25D Butterfly"
title_10d_rr          = f"{pair} - 10D Risk Reversal"
title_10d_bf          = f"{pair} - 10D Butterfly"
title_corr_template   = f"{pair} - {{window}} days Vol/Spot Correlation"
title_volvol_template = f"{pair} - {{window}} days ATM Vol de Vol"
title_beta_template   = f"{pair} - {{window}} days Vol Beta (Vol pts per 1% Spot Move)"
title_zscore_template = f"{pair} - {{window}} days Vol Z-Score"
title_meanz_template  = f"{pair} - {{window}} days Mean Vol Z-Score"
title_beta_up_template   = f"{pair} - {{window}} days Beta Spot Up (only using spot moves > {spot_return_threshold*100:.2f}%)"
title_beta_down_template = f"{pair} - {{window}} days Beta Spot Down (only using spot moves < {-spot_return_threshold*100:.2f}%)"
title_realized_vol    = f"{pair} - Realized Volatility (Daily)"
title_calendar_template = f"{pair} - ATM Calendar Spreads Z-Score Matrix (Window={{win}} days)"

graph_order = [
    "spot",
    "realized_vol",
    "basic_categories",
    "correlation",
    "vol_of_vol",
    "zscore",
    "mean_zscore",
    "beta",
    "beta_spot_up",  
    "calendar_zscore",
    "stationarity_zscore"
]

line_style = dict(width=1.3, dash='solid')
layout_conf = dict(
    template="plotly_dark",
    autosize=False,
    width=900,
    height=500,
    plot_bgcolor="rgba(55,55,55,1)",
    paper_bgcolor="rgba(55,55,55,1)",
    margin=dict(l=60, r=80, t=80, b=60),
    dragmode='pan',
    xaxis=dict(gridcolor="rgba(255,255,255,0.3)", gridwidth=0.5, tickfont=dict(size=14)),
    yaxis=dict(gridcolor="rgba(255,255,255,0.3)", gridwidth=0.5, tickfont=dict(size=14)),
    legend=dict(
        orientation='v', x=1.02, y=0.5, xanchor='left', yanchor='middle',
        bgcolor='rgba(15,15,15,0.6)', bordercolor='rgba(200,200,200,0.4)', borderwidth=1,
        font=dict(color='white', size=12), itemsizing='constant', tracegroupgap=10
    ),
)
plotly_config = dict(scrollZoom=True)

# =============================================================================
# FONCTION POUR CALCULER UN LOG RATIO SÉCURISÉ
# =============================================================================
def safe_log_ratio(series, eps=1e-8):
    ratio = series / series.shift(1)
    ratio = ratio.clip(lower=eps)
    return np.log(ratio)

# =============================================================================
# FONCTIONS UTILITAIRES
# =============================================================================
def update_fig_title(fig, title_text):
    fig.update_layout(
        title=dict(text=title_text, x=0.5, xanchor='center',
                   font=dict(size=18, color="white", family="Arial Black"))
    )
    fig.update_layout(**layout_conf)

def connect_gaps_traces(fig):
    fig.update_traces(connectgaps=True)

def detect_category(ticker: str):
    t_up = ticker.upper().replace(" BGN CURNCY", "").strip()
    if t_up == pair.upper():
        return "Spot"
    if "V" in t_up:
        return "ATM_vol"
    if "25R" in t_up:
        return "25D RR"
    if "25B" in t_up:
        return "25D BF"
    if "10R" in t_up:
        return "10D RR"
    if "10B" in t_up:
        return "10D BF"
    return "Forward"

def extract_tenor(ticker: str):
    match = re.search(r"(\d+[WMY])", ticker.upper())
    return match.group(1) if match else np.nan

def tenor_to_float(ten_str: str) -> float:
    if not isinstance(ten_str, str):
        return np.nan
    s = ten_str.upper()
    if 'W' in s: return float(s[:-1]) / 52
    if 'M' in s: return float(s[:-1]) / 12
    if 'Y' in s: return float(s[:-1])
    return np.nan

def build_legend_info(df_cat, tenor_col="Tenor", val_col="Value", fmt=".2f"):
    last_vals = df_cat.groupby(tenor_col)[val_col].last().reset_index()
    last_vals["TenorFloat"] = last_vals[tenor_col].apply(tenor_to_float)
    last_vals.sort_values("TenorFloat", inplace=True)
    legend_map = {}
    for _, row in last_vals.iterrows():
        tn, v = row[tenor_col], row[val_col]
        legend_map[tn] = f"{tn} {v:{fmt}}" if pd.notna(tn) else f"Unknown {v:{fmt}}"
    df_cat["TenorLegend"] = df_cat[tenor_col].map(legend_map)
    sorted_legends = [legend_map[t] for t in last_vals[tenor_col]]
    return df_cat, sorted_legends

def compute_AR1_half_life(series: pd.Series) -> float:
    s = series.dropna()
    if len(s) < 5:
        return np.nan
    Y = s[1:].values
    X = s[:-1].values
    X = sm.add_constant(X)
    if len(Y) != len(X):
        return np.nan
    model = sm.OLS(Y, X, missing='drop')
    res = model.fit()
    if len(res.params) < 2:
        return np.nan
    phi = res.params[1]
    if abs(phi) >= 1:
        return np.nan
    half_life = -np.log(2) / np.log(abs(phi))
    return half_life

# =============================================================================
# FONCTION POUR S'ASSURER QUE LES DATAFRAMES CONTIENNENT LES COLONNES ATTENDUES
# =============================================================================
def ensure_columns(df, cols):
    for col in cols:
        if col not in df.columns:
            df[col] = np.nan
    return df

# =============================================================================
# RÉCUPÉRATION DES DONNÉES (BQL) ET PRÉTRAITEMENT
# =============================================================================
bq = bql.Service()
tickers = [f"{pair} BGN Curncy"]
for t in tenors:
    tickers.append(f"{pair}{'12M' if t=='1Y' else t} BGN Curncy")
    tickers.append(f"{pair}V{'1Y' if t=='1Y' else t} BGN Curncy")
    tickers.append(f"{pair}25R{'1Y' if t=='1Y' else t} BGN Curncy")
    tickers.append(f"{pair}25B{'1Y' if t=='1Y' else t} BGN Curncy")
    tickers.append(f"{pair}10R{'1Y' if t=='1Y' else t} BGN Curncy")
    tickers.append(f"{pair}10B{'1Y' if t=='1Y' else t} BGN Curncy")

px_item = bq.data.px_last(dates=bq.func.range(start_date, end_date))
req = bql.Request(tickers, px_item)
resp = bq.execute(req)
df_raw = resp[0].df().reset_index()
px_col = [c for c in df_raw.columns if "PX_LAST" in c.upper()]
if not px_col:
    raise SystemExit("No PX_LAST column.")
df_raw.rename(columns={px_col[0]: "Value"}, inplace=True)
df_raw["Category"] = df_raw["ID"].apply(detect_category)
df_raw["Tenor"] = df_raw["ID"].apply(extract_tenor)
df_raw["DATE"] = pd.to_datetime(df_raw["DATE"])
df_raw = df_raw[(df_raw["DATE"] >= pd.to_datetime(start_date)) & (df_raw["DATE"] <= pd.to_datetime(end_date))]
df_raw = df_raw[df_raw["DATE"].dt.dayofweek < 5]
df_raw.sort_values("DATE", inplace=True)

# =============================================================================
# VARIABLES GLOBALES POUR LE RÉCAPITULATIF
# =============================================================================
df_spot_return   = pd.DataFrame()
df_corr_final    = pd.DataFrame()
df_volvol_final  = pd.DataFrame()
df_beta_final    = pd.DataFrame()
df_zscore_final  = pd.DataFrame()
df_beta_up_down  = pd.DataFrame()
df_calendar_info = pd.DataFrame()

# =============================================================================
# 1) PLOT SPOT
# =============================================================================
def plot_spot():
    spot_df = df_raw[df_raw["Category"]=="Spot"].copy()
    if spot_df.empty:
        return
    last_spot = spot_df["Value"].iloc[-1]
    fig = px.line(spot_df, x="DATE", y="Value", title="")
    fig.update_traces(name=f"Spot {last_spot:.4f}", showlegend=True, line=dict(color='white', width=2.0))
    connect_gaps_traces(fig)
    update_fig_title(fig, title_spot)
    fig.show(config=plotly_config)

# =============================================================================
# 2) PLOT CATÉGORIES (ATM, 25D/10D RR/BF)
# =============================================================================
def plot_basic_categories():
    categories = [
        ("ATM_vol", title_atm_vol, False),
        ("25D RR", title_25d_rr, True),
        ("25D BF", title_25d_bf, False),
        ("10D RR", title_10d_rr, True),
        ("10D BF", title_10d_bf, False)
    ]
    for cat, title_text, zero_line in categories:
        df_cat = df_raw[df_raw["Category"] == cat].copy()
        if df_cat.empty:
            continue
        df_cat, sorted_legs = build_legend_info(df_cat)
        fig = px.line(df_cat, x="DATE", y="Value", color="TenorLegend",
                      category_orders={"TenorLegend": sorted_legs})
        fig.update_traces(line=line_style)
        connect_gaps_traces(fig)
        update_fig_title(fig, title_text)
        if zero_line:
            fig.add_hline(y=0, line_color='red', line_width=2)
        fig.update_layout(legend_title_text="")
        fig.show(config=plotly_config)

# =============================================================================
# 3) CORRÉLATION ROULANTE (SPOT vs. ATM_vol)
# =============================================================================
def plot_correlation():
    global df_corr_final
    window = rolling_windows[0]
    spot = df_raw[df_raw["Category"]=="Spot"].copy()
    spot["Return"] = safe_log_ratio(spot["Value"])
    spot.set_index("DATE", inplace=True)
    atm = df_raw[df_raw["Category"]=="ATM_vol"].copy()
    atm.set_index("DATE", inplace=True)
    corr_df = pd.DataFrame(index=spot.index)
    for tenor in atm["Tenor"].unique():
        sub = atm[atm["Tenor"]==tenor].copy()
        sub["Return"] = safe_log_ratio(sub["Value"])
        merged = spot[["Return"]].join(sub[["Return"]], lsuffix='_spot', rsuffix='_atm')
        corr_rolling = merged['Return_spot'].rolling(window, min_periods=window).corr(merged['Return_atm'])
        corr_df[tenor] = corr_rolling
    corr_df.reset_index(inplace=True)
    df_corr_long = corr_df.melt(id_vars="DATE", var_name="Tenor", value_name="Corr")
    df_corr_final = df_corr_long.copy()
    df_corr_long, sorted_legs = build_legend_info(df_corr_long, "Tenor", "Corr", fmt=".2%")
    fig = px.line(df_corr_long, x="DATE", y="Corr", color="TenorLegend",
                  category_orders={"TenorLegend": sorted_legs})
    fig.update_traces(line=line_style)
    connect_gaps_traces(fig)
    update_fig_title(fig, title_corr_template.format(window=window))
    fig.update_layout(yaxis_tickformat=".2%")
    fig.add_shape(type="line", x0=df_corr_long["DATE"].min(), x1=df_corr_long["DATE"].max(),
                  y0=0, y1=0, line=dict(color="red"))
    fig.update_layout(legend_title_text="")
    fig.show(config=plotly_config)

# =============================================================================
# 4) VOL DE VOL
# =============================================================================
def plot_vol_of_vol():
    global df_volvol_final
    window = rolling_windows[0]
    atm = df_raw[df_raw["Category"]=="ATM_vol"].copy()
    atm.set_index("DATE", inplace=True)
    volvol_df = pd.DataFrame(index=atm.index)
    for tenor in atm["Tenor"].unique():
        sub = atm[atm["Tenor"]==tenor].copy()
        sub["VolReturn"] = np.log(sub["Value"] / sub["Value"].shift(1))
        vol = sub["VolReturn"].rolling(window, min_periods=window).std() * np.sqrt(260)
        volvol_df[tenor] = vol
    volvol_df.reset_index(inplace=True)
    df_m = volvol_df.melt(id_vars="DATE", var_name="Tenor", value_name="VolOfVol")
    df_volvol_final = df_m.copy()
    df_m, sorted_legs = build_legend_info(df_m, "Tenor", "VolOfVol", fmt=".2%")
    fig = px.line(df_m, x="DATE", y="VolOfVol", color="TenorLegend",
                  category_orders={"TenorLegend": sorted_legs},
                  labels={"VolOfVol": "Vol de Vol (annualisé, base 260)"})
    fig.update_traces(line=line_style)
    connect_gaps_traces(fig)
    update_fig_title(fig, title_volvol_template.format(window=window))
    fig.update_layout(yaxis_tickformat=".2%")
    fig.add_shape(type="line", x0=volvol_df["DATE"].min(), x1=volvol_df["DATE"].max(),
                  y0=0, y1=0, line=dict(color="red"))
    fig.update_layout(legend_title_text="")
    fig.show(config=plotly_config)

# =============================================================================
# 5) BÊTA DES VOLS
# =============================================================================
def plot_beta():
    global df_beta_final
    window = rolling_windows[0]
    spot = df_raw[df_raw["Category"]=="Spot"].copy()
    spot["Return"] = safe_log_ratio(spot["Value"])
    spot.set_index("DATE", inplace=True)
    atm = df_raw[df_raw["Category"]=="ATM_vol"].copy()
    atm.set_index("DATE", inplace=True)
    beta_df = pd.DataFrame(index=spot.index)
    for tenor in atm["Tenor"].unique():
        sub = atm[atm["Tenor"]==tenor].copy()
        sub["Return"] = safe_log_ratio(sub["Value"])
        merged = spot[["Return"]].join(sub[["Return"]], lsuffix='_spot', rsuffix='_atm')
        cov = merged["Return_atm"].rolling(window, min_periods=window).cov(merged["Return_spot"])
        var = merged["Return_spot"].rolling(window, min_periods=window).var()
        beta_df[tenor] = (cov / var) / 10.0
    beta_df.reset_index(inplace=True)
    df_melt = beta_df.melt(id_vars="DATE", var_name="Tenor", value_name="Beta")
    df_beta_final = df_melt.copy()
    df_melt, sorted_legs = build_legend_info(df_melt, "Tenor", "Beta")
    fig = px.line(df_melt, x="DATE", y="Beta", color="TenorLegend",
                  category_orders={"TenorLegend": sorted_legs},
                  labels={"Beta": "Beta (Vol pts per 1% Spot Move)"})
    fig.update_traces(line=line_style)
    connect_gaps_traces(fig)
    update_fig_title(fig, title_beta_template.format(window=window))
    fig.add_shape(type="line", x0=beta_df["DATE"].min(), x1=beta_df["DATE"].max(),
                  y0=0, y1=0, line=dict(color="red"))
    fig.update_layout(legend_title_text="")
    fig.show(config=plotly_config)

# =============================================================================
# 6) Z-SCORE par Tenor
# =============================================================================
def plot_zscore():
    global df_zscore_final
    window = rolling_windows[0]
    spot = df_raw[df_raw["Category"]=="Spot"].copy()
    spot["Return"] = safe_log_ratio(spot["Value"])
    spot.set_index("DATE", inplace=True)
    atm = df_raw[df_raw["Category"]=="ATM_vol"].copy()
    atm.set_index("DATE", inplace=True)
    z_df = pd.DataFrame(index=spot.index)
    for tenor in atm["Tenor"].unique():
        sub = atm[atm["Tenor"]==tenor].copy()
        mean_val = sub["Value"].rolling(window, min_periods=window).mean()
        std_val  = sub["Value"].rolling(window, min_periods=window).std()
        z_df[tenor] = (sub["Value"] - mean_val) / (std_val)
    z_df.reset_index(inplace=True)
    df_melt = z_df.melt(id_vars="DATE", var_name="Tenor", value_name="ZScore")
    df_zscore_final = df_melt.copy()
    df_melt, sorted_legs = build_legend_info(df_melt, "Tenor", "ZScore")
    fig = px.line(df_melt, x="DATE", y="ZScore", color="TenorLegend",
                  category_orders={"TenorLegend": sorted_legs},
                  labels={"ZScore": "Z-Score"})
    fig.update_traces(line=line_style, showlegend=True)
    connect_gaps_traces(fig)
    update_fig_title(fig, title_zscore_template.format(window=window))
    fig.add_shape(type="line", x0=z_df["DATE"].min(), x1=z_df["DATE"].max(),
                  y0=0, y1=0, line=dict(color="red"))
    fig.update_layout(legend_title_text="")
    fig.show(config=plotly_config)

# =============================================================================
# 7) Z-SCORE MOYEN
# =============================================================================
def plot_mean_zscore():
    window = rolling_windows[0]
    spot = df_raw[df_raw["Category"]=="Spot"].copy()
    spot["Return"] = safe_log_ratio(spot["Value"])
    spot.set_index("DATE", inplace=True)
    atm = df_raw[df_raw["Category"]=="ATM_vol"].copy()
    atm.set_index("DATE", inplace=True)
    z_df = pd.DataFrame(index=spot.index)
    for tenor in atm["Tenor"].unique():
        sub = atm[atm["Tenor"]==tenor].copy()
        mean_val = sub["Value"].rolling(window, min_periods=window).mean()
        std_val  = sub["Value"].rolling(window, min_periods=window).std()
        z_df[tenor] = (sub["Value"] - mean_val) / (std_val)
    z_df.reset_index(inplace=True)
    z_df["MeanZScore"] = z_df.drop(columns="DATE").mean(axis=1)
    fig = px.line(z_df, x="DATE", y="MeanZScore", labels={"MeanZScore": "Mean Z-Score"})
    connect_gaps_traces(fig)
    update_fig_title(fig, title_meanz_template.format(window=window))
    fig.add_shape(type="line", x0=z_df["DATE"].min(), x1=z_df["DATE"].max(),
                  y0=0, y1=0, line=dict(color="red"))
    last_val = z_df["MeanZScore"].iloc[-1]
    fig.update_traces(name=f"MeanZScore {last_val:.2f}", showlegend=True)
    fig.show(config=plotly_config)

# =============================================================================
# 8) BÊTA SPOT UP/DOWN
# =============================================================================
def plot_beta_spot():
    global df_beta_up_down
    window = rolling_windows[0]
    spot = df_raw[df_raw["Category"]=="Spot"].copy()
    spot["Return"] = safe_log_ratio(spot["Value"])
    spot.set_index("DATE", inplace=True)
    atm = df_raw[df_raw["Category"]=="ATM_vol"].copy()
    atm.set_index("DATE", inplace=True)
    beta_up_df = pd.DataFrame(index=spot.index)
    beta_down_df = pd.DataFrame(index=spot.index)
    for tenor in atm["Tenor"].unique():
        sub = atm[atm["Tenor"]==tenor].copy()
        sub["Return"] = safe_log_ratio(sub["Value"])
        merged = spot[["Return"]].join(sub[["Return"]], how='inner', lsuffix='_spot', rsuffix='_atm')
        up_series = pd.Series(index=merged.index, dtype=float)
        down_series = pd.Series(index=merged.index, dtype=float)
        for i in range(window - 1, len(merged)):
            slice_ = merged.iloc[i - window + 1 : i + 1]
            up_slice = slice_[slice_["Return_spot"] >= spot_return_threshold]
            down_slice = slice_[slice_["Return_spot"] <= -spot_return_threshold]
            if len(up_slice) >= 2:
                cov_up = up_slice["Return_atm"].cov(up_slice["Return_spot"])
                var_up = up_slice["Return_spot"].var()
                if var_up != 0:
                    up_series.iloc[i] = (cov_up / var_up) / 10.0
            if len(down_slice) >= 2:
                cov_down = down_slice["Return_atm"].cov(down_slice["Return_spot"])
                var_down = down_slice["Return_spot"].var()
                if var_down != 0:
                    down_series.iloc[i] = (cov_down / var_down) / 10.0
        beta_up_df[tenor] = up_series
        beta_down_df[tenor] = down_series
    beta_up_df.reset_index(inplace=True)
    beta_down_df.reset_index(inplace=True)
    df_up = beta_up_df.melt(id_vars="DATE", var_name="Tenor", value_name="Beta_Spot_UP")
    df_down = beta_down_df.melt(id_vars="DATE", var_name="Tenor", value_name="Beta_Spot_DOWN")
    df_beta_up_down = pd.merge(df_up, df_down, on=["DATE", "Tenor"], how="outer")
    # Graph Beta Spot UP
    df_m_up, sorted_legs_up = build_legend_info(df_up, "Tenor", "Beta_Spot_UP")
    fig_up = px.line(df_m_up, x="DATE", y="Beta_Spot_UP", color="TenorLegend",
                     category_orders={"TenorLegend": sorted_legs_up},
                     labels={"Beta_Spot_UP": "Beta Spot UP (Vol pts / 1% Spot Move)"})
    fig_up.update_traces(line=line_style)
    connect_gaps_traces(fig_up)
    update_fig_title(fig_up, title_beta_up_template.format(window=window))
    fig_up.add_shape(type="line", x0=beta_up_df["DATE"].min(), x1=beta_up_df["DATE"].max(),
                     y0=0, y1=0, line=dict(color="red", width=2))
    fig_up.update_layout(legend_title_text="")
    fig_up.show(config=plotly_config)
    # Graph Beta Spot DOWN
    df_m_down, sorted_legs_down = build_legend_info(df_down, "Tenor", "Beta_Spot_DOWN")
    fig_down = px.line(df_m_down, x="DATE", y="Beta_Spot_DOWN", color="TenorLegend",
                       category_orders={"TenorLegend": sorted_legs_down},
                       labels={"Beta_Spot_DOWN": "Beta Spot Down (Vol pts / 1% Spot Move)"})
    fig_down.update_traces(line=line_style)
    connect_gaps_traces(fig_down)
    update_fig_title(fig_down, title_beta_down_template.format(window=window))
    fig_down.add_shape(type="line", x0=beta_down_df["DATE"].min(), x1=beta_down_df["DATE"].max(),
                       y0=0, y1=0, line=dict(color="red", width=2))
    fig_down.update_layout(legend_title_text="")
    fig_down.show(config=plotly_config)

# =============================================================================
# 9) REALIZED VOL
# =============================================================================
def plot_realized_vol():
    spot = df_raw[df_raw["Category"]=="Spot"].copy()
    spot["Return"] = safe_log_ratio(spot["Value"])
    realized_vol_df = pd.DataFrame(index=spot.index)
    for w in realized_windows:
        realized_vol_df[f"RV_{w}d"] = spot["Return"].rolling(w, min_periods=w).std() * np.sqrt(260)
    realized_vol_df.reset_index(inplace=True)
    realized_vol_df.rename(columns={"index": "DATE"}, inplace=True)
    rv_melt = realized_vol_df.melt(id_vars="DATE", var_name="Window", value_name="RealizedVol")
    fig = px.line(rv_melt, x="DATE", y="RealizedVol", color="Window", title=title_realized_vol)
    fig.update_traces(line=line_style)
    connect_gaps_traces(fig)
    update_fig_title(fig, title_realized_vol)
    fig.update_layout(yaxis_tickformat=".2%", width=900, height=500)
    for d in fig.data:
        col_name = d.name.split("=")[1] if "Window=" in d.name else d.name
        last_val = realized_vol_df[col_name].iloc[-1]
        d.name = f"{col_name} {last_val:.2%}"
    fig.update_layout(legend_title_text="")
    fig.show(config=plotly_config)

# =============================================================================
# 10) CALENDAR SPREADS Z-SCORE + TRADE SUGGESTIONS
# =============================================================================
def plot_calendar_zscore():
    global df_calendar_info
    atm_reset = df_raw[df_raw["Category"]=="ATM_vol"].copy().reset_index(drop=True)
    atm_pivot = atm_reset.pivot(index="DATE", columns="Tenor", values="Value")
    sorted_tenors = sorted(atm_pivot.columns, key=lambda x: tenor_to_float(x))
    atm_pivot = atm_pivot[sorted_tenors]
    my_scale = [
        [0.0,  "#E0B0FF"],
        [0.25, "#E6E6FA"],
        [0.5,  "#FFFFFF"],
        [0.75, "#4169E1"],
        [1.0,  "#4169E1"]
    ]
    pair_details = {}
    window = rolling_windows[0]
    atm_recent = atm_pivot.iloc[-window:]
    n = len(sorted_tenors)
    z_matrix = np.full((n, n), np.nan)
    reversion_times = {}
    rows_list = []
    for i in range(n):
        for j in range(i+1, n):
            spread_series = atm_recent.iloc[:, j] - atm_recent.iloc[:, i]
            mean_spread = spread_series.mean()
            std_spread  = spread_series.std()
            current_spread = atm_pivot.iloc[-1, j] - atm_pivot.iloc[-1, i]
            z_sc = 0.0 if std_spread == 0 else (current_spread - mean_spread) / std_spread
            z_matrix[i, j] = z_sc
            half_life = compute_AR1_half_life(spread_series)
            reversion_times[(sorted_tenors[i], sorted_tenors[j])] = half_life
            pair_details[(sorted_tenors[i], sorted_tenors[j])] = (z_sc, current_spread, mean_spread)
            row_dict = {
                "TenorShort": sorted_tenors[i],
                "TenorLong": sorted_tenors[j],
                "Spread": current_spread,
                "MeanSpread": mean_spread,
                "Zscore": z_sc,
                "AR1_HalfLifeDays": half_life
            }
            rows_list.append(row_dict)
    df_calendar_info = pd.DataFrame(rows_list)
    fig = px.imshow(z_matrix, x=sorted_tenors, y=sorted_tenors, origin="lower",
                    color_continuous_scale=my_scale, range_color=(-3, 3),
                    labels=dict(color="Z-Score"))
    fig.update_layout(width=900, height=500, xaxis_title="Longer Tenor", yaxis_title="Shorter Tenor")
    update_fig_title(fig, title_calendar_template.format(win=window))
    annotations = []
    for i in range(n):
        for j in range(i+1, n):
            val = z_matrix[i, j]
            txt = f"{val:.2f}"
            color = "red" if val < 0 else "blue"
            annotations.append(dict(x=sorted_tenors[j], y=sorted_tenors[i], text=txt,
                                    showarrow=False, font=dict(color=color, size=12),
                                    xref="x", yref="y", xanchor="center", yanchor="middle"))
    fig.update_layout(annotations=annotations)
    fig.show(config=plotly_config)
    sorted_pairs = sorted(pair_details.items(), key=lambda x: abs(x[1][0]), reverse=True)
    top5 = sorted_pairs[:5]
    print(f"Trade Suggestions (Window = {window} days):")
    for (t_short, t_long), (z, sv, mv) in top5:
        suggestion = "No action"
        if z > 0:
            suggestion = f"Sell {t_long} ATM, Buy {t_short} ATM"
        elif z < 0:
            suggestion = f"Buy {t_long} ATM, Sell {t_short} ATM"
        hl = reversion_times.get((t_short, t_long), np.nan)
        hl_txt = f"{hl:.1f} days" if pd.notna(hl) else "N/A"
        print(f"Spread {t_short} vs {t_long}: z={z:.2f}, Spot={sv:.2f}, Mean={mv:.2f} -> {suggestion} (half-life): {hl_txt}.")
    print()

# =============================================================================
# 11) TEST DE STATIONNARITÉ DU Z-SCORE MOYEN
# =============================================================================
def stationarity_zscore():
    window = rolling_windows[0]
    spot = df_raw[df_raw["Category"]=="Spot"].copy()
    spot["Return"] = safe_log_ratio(spot["Value"])
    spot.set_index("DATE", inplace=True)
    atm = df_raw[df_raw["Category"]=="ATM_vol"].copy()
    atm.set_index("DATE", inplace=True)
    z_df = pd.DataFrame(index=spot.index)
    for tenor in atm["Tenor"].unique():
        sub = atm[atm["Tenor"]==tenor].copy()
        mean_val = sub["Value"].rolling(window, min_periods=window).mean()
        std_val  = sub["Value"].rolling(window, min_periods=window).std()
        z_df[tenor] = (sub["Value"] - mean_val) / std_val
    z_df["MeanZScore"] = z_df.mean(axis=1, skipna=True)
    mean_z_series = z_df["MeanZScore"].dropna()
    if len(mean_z_series) < 30:
        print("Pas assez de points pour un test ADF sur le MeanZScore.")
        return
    print("[Test stationnarité du MeanZScore sur toute la période]")
    adf_res = adfuller(mean_z_series, autolag='AIC')
    stat_adf = adf_res[0]
    p_value = adf_res[1]
    crit_values = adf_res[4]
    print(f"ADF Statistic: {stat_adf:.4f}, p-value: {p_value:.4f}")
    for k, v in crit_values.items():
        print(f"   Crit {k}: {v:.4f}")
    if p_value < 0.05:
        print("Conclusion: le MeanZScore semble stationnaire (p<0.05).")
    else:
        print("Conclusion: le MeanZScore n'est pas stationnaire au seuil de 5%.")
    # Calcul de la half-life du MeanZScore
    hl = compute_AR1_half_life(mean_z_series)
    hl_txt = f"{hl:.1f} days" if pd.notna(hl) else "N/A"
    print(f"(half-life): {hl_txt}.")
    print()

# =============================================================================
# 12) CRÉATION DU DATAFRAME RÉCAPITULATIF FINAL
# =============================================================================
def create_summary_table():
    df_base = df_raw[["DATE", "Category", "Tenor", "Value"]].copy()
    df_corr2 = df_corr_final.rename(columns={"Corr": "CorrWithSpot"})
    df_volvol2 = df_volvol_final.copy()
    df_beta2 = df_beta_final.copy()
    df_zscore2 = df_zscore_final.copy()
    df_betaud = df_beta_up_down.copy()
    df_base = ensure_columns(df_base, ["DATE", "Tenor"])
    df_corr2 = ensure_columns(df_corr2, ["DATE", "Tenor", "CorrWithSpot"])
    df_volvol2 = ensure_columns(df_volvol2, ["DATE", "Tenor", "VolOfVol"])
    df_beta2 = ensure_columns(df_beta2, ["DATE", "Tenor", "Beta"])
    df_zscore2 = ensure_columns(df_zscore2, ["DATE", "Tenor", "ZScore"])
    df_betaud = ensure_columns(df_betaud, ["DATE", "Tenor", "Beta_Spot_UP", "Beta_Spot_DOWN"])

    df_merged = pd.merge(df_base, df_corr2, on=["DATE", "Tenor"], how="outer")
    df_merged = pd.merge(df_merged, df_volvol2, on=["DATE", "Tenor"], how="outer")
    df_merged = pd.merge(df_merged, df_beta2, on=["DATE", "Tenor"], how="outer")
    df_merged = pd.merge(df_merged, df_zscore2, on=["DATE", "Tenor"], how="outer")
    df_merged = pd.merge(df_merged, df_betaud, on=["DATE", "Tenor"], how="outer")
    df_merged.sort_values(["DATE", "Tenor"], inplace=True)
    df_merged["Return"] = np.nan
    for tnr in df_merged["Tenor"].dropna().unique():
        mask = (df_merged["Tenor"] == tnr)
        df_merged.loc[mask, "Return"] = np.log(df_merged.loc[mask,   "Value"]   / df_merged.loc[mask, "Value"].shift(1))
    df_summary = df_merged
    print("\n[Création du DF récapitulatif terminé]")
    print("df_summary colonnes :", df_summary.columns.tolist())
    print(df_summary.head(10))
    return df_summary

# =============================================================================
# TABLEAU DES FONCTIONS DE GRAPHIQUES
# =============================================================================
graph_functions = {
    "spot":              plot_spot,
    "basic_categories":  plot_basic_categories,
    "correlation":       plot_correlation,
    "vol_of_vol":        plot_vol_of_vol,
    "beta":              plot_beta,
    "zscore":            plot_zscore,
    "mean_zscore":       plot_mean_zscore,
    "beta_spot_up":      plot_beta_spot,
    "beta_spot_down":    lambda: None,
    "realized_vol":      plot_realized_vol,
    "calendar_zscore":   plot_calendar_zscore,
    "stationarity_zscore": stationarity_zscore
}

# =============================================================================
# EXÉCUTION DES SECTIONS
# =============================================================================
for key in graph_order:
    func = graph_functions.get(key)
    if func is not None:
        func()

print("[OK] Script terminé (Graphiques & Calculs).")

